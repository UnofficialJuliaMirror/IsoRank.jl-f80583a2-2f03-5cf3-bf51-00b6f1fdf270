{
    "docs": [
        {
            "location": "/", 
            "text": "Introduction\n\n\nIsoRank.jl is a Julia implementation of the IsoRank matrix as described in \"Global alignment of multiple protein interaction networks with application to functional orthology detection\", Rohit Singh, Jinbo Xu, and Bonnie Berger (2008).\n\n\nThe IsoRank matrix is calculated by creating the product graph of two networks, and then performing PageRank on the product graph. PageRank is done by using the power method to calculate the dominant eigenvector of the modified adjacency matrix of the product graph. Since IsoRank.jl doesn't explicitly build the product graph in order to perform power iteration, it has much better time and space complexity compared to other implementations of IsoRank.\n\n\n\n\nInstallation\n\n\nIsoRank can be installed as follows. We also use the NetalignUtils to read networks.\n\n\nPkg.add(\nIsoRank\n)\nPkg.add(\nNetalignUtils\n)\n\n\n\n\n\n\nExample usage\n\n\nWe load an example network from the \"examples/\" directory and create an IsoRank matrix between the network and itself. Unlike the original paper which performs no damping when using network topology alone, we give it a damping factor of 0.85 in order to calculate a good IsoRank matrix using just network topology.\n\n\nusing NetalignUtils\nusing IsoRank\n\nG1 = readgw(\n0Krogan_2007_high.gw\n).G\nG2 = G1\n\nR = isorank(G1, G2, damping=0.85)\n\nR ./= maximum(R)\ntruemap = 1:size(G2,1)\nrandmap = randperm(size(G2,1))\nprintln(sum(R[sub2ind(size(R),truemap,truemap)]))\nprintln(sum(R[sub2ind(size(R),truemap,randmap)]))\n\n\n\n\nAssuming we have a matrix of node similarities, we can calculate the IsoRank matrix using node similarities as follows, where \nb\n is a matrix of node similarities.\n\n\nb = rand(size(G1,1), size(G2,1))\n\nR = isorank(G1, G2, b, 0.5)\n\n\n\n\nMaximum number of iterations and error tolerance can be set as follows.\n\n\nR = isorank(G1, G2, b, 0.5, maxiter=20, tol=1e-5)\n\n\n\n\nWe can extract the modified adjacency matrix, \nL\n, of the product graph as follows. \nvec(R)\n is the dominant eigenvector and \nres[1]\n is the corresponding eigenvalue of \nL\n.\n\n\nR,res,L = isorank(G1, G2, damping=0.85, details=true)\n\nprintln(norm(L * vec(R) - res[1] * vec(R),1))", 
            "title": "Introduction"
        }, 
        {
            "location": "/#introduction", 
            "text": "IsoRank.jl is a Julia implementation of the IsoRank matrix as described in \"Global alignment of multiple protein interaction networks with application to functional orthology detection\", Rohit Singh, Jinbo Xu, and Bonnie Berger (2008).  The IsoRank matrix is calculated by creating the product graph of two networks, and then performing PageRank on the product graph. PageRank is done by using the power method to calculate the dominant eigenvector of the modified adjacency matrix of the product graph. Since IsoRank.jl doesn't explicitly build the product graph in order to perform power iteration, it has much better time and space complexity compared to other implementations of IsoRank.", 
            "title": "Introduction"
        }, 
        {
            "location": "/#installation", 
            "text": "IsoRank can be installed as follows. We also use the NetalignUtils to read networks.  Pkg.add( IsoRank )\nPkg.add( NetalignUtils )", 
            "title": "Installation"
        }, 
        {
            "location": "/#example-usage", 
            "text": "We load an example network from the \"examples/\" directory and create an IsoRank matrix between the network and itself. Unlike the original paper which performs no damping when using network topology alone, we give it a damping factor of 0.85 in order to calculate a good IsoRank matrix using just network topology.  using NetalignUtils\nusing IsoRank\n\nG1 = readgw( 0Krogan_2007_high.gw ).G\nG2 = G1\n\nR = isorank(G1, G2, damping=0.85)\n\nR ./= maximum(R)\ntruemap = 1:size(G2,1)\nrandmap = randperm(size(G2,1))\nprintln(sum(R[sub2ind(size(R),truemap,truemap)]))\nprintln(sum(R[sub2ind(size(R),truemap,randmap)]))  Assuming we have a matrix of node similarities, we can calculate the IsoRank matrix using node similarities as follows, where  b  is a matrix of node similarities.  b = rand(size(G1,1), size(G2,1))\n\nR = isorank(G1, G2, b, 0.5)  Maximum number of iterations and error tolerance can be set as follows.  R = isorank(G1, G2, b, 0.5, maxiter=20, tol=1e-5)  We can extract the modified adjacency matrix,  L , of the product graph as follows.  vec(R)  is the dominant eigenvector and  res[1]  is the corresponding eigenvalue of  L .  R,res,L = isorank(G1, G2, damping=0.85, details=true)\n\nprintln(norm(L * vec(R) - res[1] * vec(R),1))", 
            "title": "Example usage"
        }, 
        {
            "location": "/funs/", 
            "text": "Functions\n\n\n#\n\n\nIsoRank.isorank\n \n \nMethod\n.\n\n\nisorank(G1::SparseMatrixCSC, G2::SparseMatrixCSC,\n        b::AbstractMatrix, alpha::Real; \nkeyword arguments\n)\n\n\n\n\nCreates the IsoRank matrix. That is, finds the pagerank values of the modified adjacency matrix of the product graph of G1 and G2. b acts as node restarts allowing you to incorporate external information.     (See Rohit Singh, Jinbo Xu, and Bonnie Berger. (2008) Global alignment of multiple protein interaction networks with application to functional orthology detection, Proc. Natl. Acad. Sci. USA, 105:12763-12768.)\n\n\nArguments\n\n\n\n\nG1,G2\n : two adjacency matrices\n\n\nb\n : matrix of node similarities, not necessarily normalized\n\n\nalpha\n: weight between edge and node conservation\n\n\n\n\nKeyword arguments\n\n\n\n\ndetails=false\n : if true, returns (R,res,L) where R is the IsoRank matrix, res is the power method details structure, L is the linear operator that the power method finds the eigenvector of; if false, returns R\n\n\nSee \npowermethod!\n for other keyword arguments\n\n\n\n\nsource\n\n\n#\n\n\nIsoRank.isorank\n \n \nMethod\n.\n\n\nisorank(G1::SparseMatrixCSC, G2::SparseMatrixCSC,\n        [damping=0.85]; \nkeyword arguments\n)\n\n\n\n\nIf you don't have node similarities, you can still create a decent IsoRank matrix by doing damping like PageRank does. This is unlike the original paper that creates a bad IsoRank matrix when b = 0 or alpha = 1.\n\n\nsource\n\n\n#\n\n\nIsoRank.powermethod!\n \n \nMethod\n.\n\n\npowermethod!(A, x; \nkeyword arguments\n) -\n radius, x, [log/history]\n\n\n\n\nPerforms power method in order to find the dominant eigenvector of the linear operator A. Eigenvector is normalized w.r.t. L_1 norm. Modifies initial eigenvector estimate x.\n\n\nArguments\n\n\n\n\nA\n : linear operator\n\n\nx\n : initial estimate of the eigenvector, not necessarily normalized\n\n\n\n\nKeyword arguments\n\n\n\n\nmaxiter\n : maximum # of iterations\n\n\ntol=eps(Float64) * size(A,2)\n : error tolerance in L_1\n\n\nlog=true,verbose=true\n : logging and printing\n\n\n\n\nsource\n\n\n#\n\n\nIsoRank.kronlm\n \n \nMethod\n.\n\n\nkronlm([T], A, B)\n\n\n\n\nKronecker product of A and B, stored as a linear operator (from LinearMaps.jl) so that you don't have to create the actual matrix. This is much faster than creating the matrix like the original paper does: O(|E|) instead of O(|E|^2) for each step of the power iteration where |E| is the average number of edges in the graphs\n\n\nArguments\n\n\n\n\nA,B\n : linear operators with multiply and transpose operations\n\n\nT\n : element type of the resulting linear operator\n\n\n\n\nsource", 
            "title": "Functions"
        }, 
        {
            "location": "/funs/#functions", 
            "text": "#  IsoRank.isorank     Method .  isorank(G1::SparseMatrixCSC, G2::SparseMatrixCSC,\n        b::AbstractMatrix, alpha::Real;  keyword arguments )  Creates the IsoRank matrix. That is, finds the pagerank values of the modified adjacency matrix of the product graph of G1 and G2. b acts as node restarts allowing you to incorporate external information.     (See Rohit Singh, Jinbo Xu, and Bonnie Berger. (2008) Global alignment of multiple protein interaction networks with application to functional orthology detection, Proc. Natl. Acad. Sci. USA, 105:12763-12768.)  Arguments   G1,G2  : two adjacency matrices  b  : matrix of node similarities, not necessarily normalized  alpha : weight between edge and node conservation   Keyword arguments   details=false  : if true, returns (R,res,L) where R is the IsoRank matrix, res is the power method details structure, L is the linear operator that the power method finds the eigenvector of; if false, returns R  See  powermethod!  for other keyword arguments   source  #  IsoRank.isorank     Method .  isorank(G1::SparseMatrixCSC, G2::SparseMatrixCSC,\n        [damping=0.85];  keyword arguments )  If you don't have node similarities, you can still create a decent IsoRank matrix by doing damping like PageRank does. This is unlike the original paper that creates a bad IsoRank matrix when b = 0 or alpha = 1.  source  #  IsoRank.powermethod!     Method .  powermethod!(A, x;  keyword arguments ) -  radius, x, [log/history]  Performs power method in order to find the dominant eigenvector of the linear operator A. Eigenvector is normalized w.r.t. L_1 norm. Modifies initial eigenvector estimate x.  Arguments   A  : linear operator  x  : initial estimate of the eigenvector, not necessarily normalized   Keyword arguments   maxiter  : maximum # of iterations  tol=eps(Float64) * size(A,2)  : error tolerance in L_1  log=true,verbose=true  : logging and printing   source  #  IsoRank.kronlm     Method .  kronlm([T], A, B)  Kronecker product of A and B, stored as a linear operator (from LinearMaps.jl) so that you don't have to create the actual matrix. This is much faster than creating the matrix like the original paper does: O(|E|) instead of O(|E|^2) for each step of the power iteration where |E| is the average number of edges in the graphs  Arguments   A,B  : linear operators with multiply and transpose operations  T  : element type of the resulting linear operator   source", 
            "title": "Functions"
        }
    ]
}